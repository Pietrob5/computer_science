

<h1 align="center">Informatica</h1>
<h4 align="center">
    <p>
        <b>Italiano</b> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README.md">English</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_es.md">Español</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_fr.md">Français</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_bn.md">বাংলা</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_ta.md">தமிழ்</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_guj.md">ગુજરાતી</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_pt.md">Portuguese</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_hi.md">हिंदी</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_te.md">తెలుగు</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_ro.md">Română</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_ar.md">العربية</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_np.md">Nepali</a> |
        <a href="https://github.com/shhossain/computer_science/blob/main/README_cn.md">简体中文</a>
    </p>
</h4>

## Linee guida per i contributi
Se sei interessato a contribuire a questo progetto, prenditi un momento per leggere [CONTRIBUTING.md](https://github.com/shhossain/computer_science/blob/main/CONTRIBUTING.md) per istruzioni dettagliate su come iniziare. I tuoi contributi sono molto apprezzati!

<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->
[![All Contributors](https://img.shields.io/badge/all_contributors-153-orange.svg?style=flat-square)](#contributors-)
<!-- ALL-CONTRIBUTORS-BADGE:END -->

## Indice dei Contenuti

- [Introduzione](#introduzione)
- [Computer Elettronico](#computer-elettronico)
- [Logica Booleana](#logica-booleana)
- [Circuiti Digitali](#circuiti-digitali)
- [Sistemi Numerici](#sistemi-numerici)
- [Unità di Elaborazione Centrale (CPU)](#unità-di-elaborazione-centrale-cpu)
- [Registri, Cache e RAM](#registri-cache-e-ram)
- [Istruzioni e Programma](#istruzioni-e-programma)
- [Linguaggi di Programmazione](#linguaggi-di-programmazione)
- [Tipi di Dati](#tipi-di-dati)
- [Istruzioni e Funzioni](#istruzioni-e-funzioni)
- [Strutture Dati](#strutture-dati)
- [Algoritmi](#algoritmi)
- [Alan Turing](#alan-turing)
- [Ingegneria del Software](#ingegneria-del-software)
- [Scienza dei Dati](#scienza-dei-dati)
- [Circuiti Integrati](#circuiti-integrati)
- [Programmazione Orientata agli Oggetti](#programmazione-orientata-agli-oggetti)
- [Programmazione Funzionale](#programmazione-funzionale)
- [Sistemi Operativi](#sistemi-operativi)
- [Memoria e Archiviazione](#memoria-e-archiviazione)
- [File System](#file-system)
- [Cloud Computing](#cloud-computing)
- [Apprendimento Automatico](#apprendimento-automatico)
- [Tecnologia Web](#tecnologia-web)
- [Reti](#reti)
- [Internet](#internet)
- [DBMS (Sistema di Gestione di Database)](#dbms)
- [Crittografia](#crittografia)
- [Teoria della Computazione](#teoria-della-computazione)


## Introduzione

L'informatica è lo studio dei computer e del calcolo e delle loro applicazioni teoriche e pratiche. L'informatica applica i principi della matematica, dell'ingegneria e della logica a una moltitudine di problemi, tra cui la formulazione di algoritmi, lo sviluppo di software/hardware e l'intelligenza artificiale.


## [Computer Elettronico](Electronic%20Computer/readme.md)
Un dispositivo che esegue calcoli, in particolare una macchina elettronica programmabile che esegue operazioni matematiche o logiche ad alta velocità, o che assembla, memorizza, correla o elabora in altro modo informazioni.

## [Logica Booleana](Boolean%20Logic/readme.md)
La logica booleana è un ramo della matematica che si occupa dei valori di verità e falsità. È un sistema di logica che utilizza solo due valori, 0 e 1, per rappresentare rispettivamente falso e vero. È anche conosciuta come algebra booleana, dal nome di George Boole, che l'ha descritta per la prima volta nel 1854.

### Operatori Booleani Comuni
| Operatore | Nome |               Descrizione               |
| :------: | :--: | :-------------------------------------: |
|    !     | NOT  |    Nega il valore dell'operando.    |
|    &&    | AND  | Restituisce **vero** se entrambi gli operandi sono veri. |
|   \|\|   |  OR  | Restituisce **vero** se uno o entrambi gli operandi sono veri. |

### Operatori Booleani Interessanti
| Operatore | Nome |               Descrizione               |
| :------: | :--: | :-------------------------------------: |
|    ()    | Parentesi     |   Permette di raggruppare parole chiave e controllare l'ordine in cui i termini verranno cercati.    |
|    “”    | Virgolette | Fornisce risultati con la frase esatta. |
|   *      |  Asterisco       | Fornisce risultati contenenti una variazione della parola chiave. |
|   ⊕     |  XOR            | Restituisce **vero** se gli operandi sono diversi |
|   ⊽      |  NOR            | Restituisce **vero** se tutti gli operandi sono falsi. |
|   ⊼      |  NAND           | Restituisce **falso** solo se entrambi i valori dei suoi due input sono veri. |

## [Circuiti Digitali](Digital%20Circuits/readme.md)

I circuiti digitali si occupano di segnali booleani (1 e 0). Sono i blocchi fondamentali di un computer. Sono i componenti e i circuiti utilizzati per creare unità di processore e unità di memoria essenziali per un sistema informatico.

### Tavole di Verità

Le tavole di verità sono tabelle matematiche utilizzate nella progettazione logica e dei circuiti digitali. Aiutano a mappare la funzionalità di un circuito. Possiamo utilizzarle per aiutare a progettare circuiti digitali complessi.

Le tavole di verità hanno 1 colonna per ogni variabile di input e 1 colonna finale che mostra tutti i possibili risultati dell'operazione logica che la tavola rappresenta.

### Tipi di Circuiti Digitali

Ci sono 2 tipi di circuiti digitali: Combinatori e Sequenziali

- **Circuiti Combinatori**: In questo tipo di circuito digitale, l'output dipende dall'input che riceve in un istante. Questo tipo di circuito rimarrà costante rispetto al suo input.
- **Circuiti Sequenziali**: In questo tipo di circuito digitale, l'output dipende non solo dall'input che riceve in un istante ma anche dal precedente input che ha ricevuto. L'output generato dal precedente input viene trasferito nell'output dell'input corrente.

### Metodologia di Progettazione

Quando si progetta un circuito digitale, soprattutto complesso, è importante utilizzare strumenti dell'algebra booleana per aiutare nel processo di progettazione (esempio: mappa di Karnaugh). È anche importante suddividere tutto in circuiti più piccoli ed esaminare la tavola di verità necessaria per quel circuito più piccolo. Non cercare di affrontare tutto il circuito in una volta, suddividilo e metti gradualmente insieme i pezzi.

## [Sistemi Numerici](Number%20System/readme.md#number-systems)
I sistemi numerici sono sistemi matematici per esprimere numeri. Un sistema numerico consiste in un insieme di simboli utilizzati per rappresentare numeri e un insieme di regole per manipolare

 quei simboli. I simboli utilizzati in un sistema numerico sono chiamati numerali.

### [Tipi di Sistemi Numerici](Number%20System/readme.md#types-of-number-systems)
- [Sistema Numerico Posizionale](Number%20System/readme.md#positional-numeral-system)
- [Sistema Notazionale a Segno e Valore](Number%20System/readme.md#sign-value-notation-system)

### [Sistemi Numerici Posizionali Comuni](Number%20System/readme.md#common-positional-number-systems)
- [Binario](Number%20System/readme.md#binary)
- [Ottale](Number%20System/readme.md#octal)
- [Decimale](Number%20System/readme.md#decimal)
- [Esadecimale](Number%20System/readme.md#hexadecimal)


### Importanza del Binario
Il binario è un sistema numerico a base 2 inventato da Gottfried Leibniz composto solo da due numeri o cifre: 0 (zero) e 1 (uno). Questo sistema numerico è alla base di tutto il codice binario, utilizzato per scrivere dati digitali come le istruzioni del processore del computer utilizzate ogni giorno. Gli 0 e i 1 nel binario rappresentano rispettivamente SPENTO o ACCESO. In un transistor, uno "0" rappresenta l'assenza di flusso di elettricità, e uno "1" rappresenta che l'elettricità è permessa di fluire. In questo modo, i numeri vengono rappresentati fisicamente all'interno del dispositivo di calcolo, permettendo i calcoli.

 
Il binario è ancora il linguaggio principale per i computer ed è utilizzato con l'elettronica e l'hardware del computer per le seguenti ragioni:

- È un design semplice ed elegante.
- Il metodo 0 e 1 del binario è rapido per rilevare lo stato spento (falso) o acceso (vero) di un segnale elettrico.
- Avere solo due stati posti a distanza in un segnale elettrico lo rende meno suscettibile alle interferenze elettriche.
- I poli positivi e negativi dei supporti magnetici sono rapidamente tradotti in binario.
- Il binario è il modo più efficiente per controllare i circuiti logici.


## [Unità di Elaborazione Centrale (CPU)](CPU/readme.md#central-processing-unitcpu)
L'Unità di Elaborazione Centrale (CPU) è la parte più importante di qualsiasi computer. La CPU invia segnali per controllare le altre parti del computer, quasi come un cervello controlla un corpo. La CPU è una macchina elettronica che esegue un elenco di cose da fare del computer, chiamate istruzioni. Legge l'elenco delle istruzioni ed esegue (esegue) ciascuna in ordine. Un elenco di istruzioni che una CPU può eseguire è un programma per computer. Una CPU può elaborare più di un'istruzione alla volta su sezioni chiamate "core". Una CPU con quattro core può elaborare quattro programmi contemporaneamente. La CPU stessa è composta da tre componenti principali. Sono:
1. [Unità di Memoria o di Archiviazione](CPU/readme.md#memory-or-storage-unit)
2. [Unità di Controllo](CPU/readme.md#control-unit)
3. [Unità Aritmetica e Logica (ALU)](CPU/readme.md#arithmetic-and-logic-unit-alu)



## [Registri, Cache e RAM](/Registers%20Cache%20and%20RAM)

### [Registro](/Registers%20Cache%20and%20RAM/readme.md#register)
I registri sono piccole quantità di memoria ad alta velocità contenute all'interno della CPU. I registri sono una raccolta di "flip-flop" (un circuito utilizzato per memorizzare 1 bit di memoria). Vengono utilizzati dal processore per memorizzare piccole quantità di dati necessari durante l'elaborazione. Una CPU può avere diversi set di registri che vengono chiamati "core". I registri aiutano anche nelle operazioni aritmetiche e logiche.

Le operazioni aritmetiche sono calcoli matematici eseguiti dalla CPU su dati numerici memorizzati nei registri. Queste operazioni includono addizione, sottrazione, moltiplicazione e divisione. Le operazioni logiche sono calcoli booleani eseguiti dalla CPU su dati binari memorizzati nei registri. Queste operazioni includono confronti (ad esempio, verificare se due valori sono uguali) e operazioni logiche (ad esempio, AND, OR, NOT).

I registri sono essenziali per eseguire queste operazioni perché consentono alla CPU di accedere rapidamente e manipolare piccole quantità di dati. Memorizzando i dati frequentemente utilizzati nei registri, la CPU può evitare il processo più lento di recupero dei dati dalla memoria.

Quantità maggiori di dati possono essere memorizzate nella Cache, una memoria molto veloce situata sullo stesso circuito integrato dei registri. La cache viene utilizzata per i dati accessibili frequentemente mentre il programma è in esecuzione. Quantità ancora maggiori di dati possono essere memorizzate nella RAM. La RAM è l'acronimo di "random-access memory", un tipo di memoria che contiene dati e istruzioni che sono stati spostati dall'archiviazione su disco fino a quando il processore ne avrà bisogno.


### [Cache](/Registers%20Cache%20and%20RAM/readme.md#cache)
La memoria cache è un componente del computer basato su chip che rende più efficiente il recupero dei dati dalla memoria del computer. Funziona come un'area di archiviazione temporanea in modo che il processore del computer possa recuperare facilmente i dati. Questa area di archiviazione temporanea, nota come cache, è più facilmente disponibile per il processore rispetto alla fonte di memoria principale del computer, che è tipicamente una forma di DRAM.

La memoria cache viene talvolta chiamata memoria della CPU (unità di elaborazione centrale) perché è tipicamente integrata direttamente nel chip della CPU o posizionata su un chip separato che ha un bus di interconnessione separato con la CPU. Pertanto, è più accessibile al processore e in grado di aumentare l'efficienza perché è fisicamente vicina al processore.

Per essere vicina al processore, la memoria cache deve essere molto più piccola rispetto alla memoria principale. Di conseguenza, ha meno spazio di archiviazione. È anche più costosa della memoria principale, poiché è un chip più complesso che offre prestazioni superiori.

Ciò che sacrifica in termini di dimensioni e prezzo, lo compensa in termini di velocità. La memoria cache funziona da 10 a 100 volte più velocemente della RAM, richiedendo solo pochi nanosecondi per rispondere a una richiesta della CPU.

Il nome dell'hardware effettivo utilizzato per la memoria cache è memoria statica ad accesso casuale ad alta velocità (SRAM). Il nome dell'hardware utilizzato nella memoria principale di un computer è memoria dinamica ad accesso casuale (DRAM).

La memoria cache non deve essere confusa con il termine più ampio cache. Le cache sono archivi di dati temporanei che possono esistere sia nell'hardware che nel software. La memoria cache si riferisce al componente hardware specifico che consente ai computer di creare cache a vari livelli della rete. Una cache è un componente hardware o software utilizzato per memorizzare temporaneamente qualcosa, tipicamente dati, in un ambiente informatico.


### [RAM](/Registers%20Cache%20and%20RAM/readme.md#ram)
La RAM (memoria ad accesso casuale) è una forma di memoria del computer che può essere letta e modificata in qualsiasi ordine, tipicamente utilizzata per memorizzare dati di lavoro e codice macchina. Un dispositivo di memoria ad accesso casuale consente agli elementi di dati di essere letti o scritti in quasi lo stesso tempo indipendentemente dalla posizione fisica dei dati all'interno della memoria, a differenza di altri media di archiviazione di dati ad accesso diretto (come dischi rigidi, CD-RW, DVD-RW e le vecchie memorie a nastro e a tamburo), dove il tempo richiesto per leggere e scrivere elementi di dati varia significativamente a seconda delle loro posizioni fisiche sul supporto di registrazione, a causa di limitazioni meccaniche come la velocità di rotazione dei supporti e il movimento del braccio.


## [Istruzioni e Programma](Not-Added)
Nell'informatica, un'istruzione è una singola operazione di un processore definita dal set di istruzioni del processore. Un programma per computer è un elenco di istruzioni che dicono al computer cosa fare. Tutto ciò che un computer fa viene realizzato utilizzando un programma per computer. I programmi memorizzati nella memoria di un computer ("programmazione interna") consentono al computer di fare una cosa dopo l'altra, anche con pause tra un'operazione e l'altra.

## [Linguaggi di Programmazione](/Programming_Languages/readme.md)
Un linguaggio di programmazione è un insieme di regole che converte stringhe, o elementi grafici di programma nel caso di linguaggi di programmazione visuale, in vari tipi di output in codice macchina. I linguaggi di programmazione sono un tipo di linguaggio informatico utilizzato nella programmazione per implementare algoritmi.

I linguaggi di programmazione sono spesso divisi in due ampie categorie:
1. Il linguaggio ad alto livello utilizza una sintassi simile alla lingua inglese. Il codice sorgente viene convertito in codice macchina comprensibile tramite un compilatore o un interprete. Java e Python sono alcuni esempi di linguaggi di programmazione ad alto livello. Questi sono generalmente più lenti dei linguaggi a basso livello, ma sono più facili da utilizzare.
2. I linguaggi di programmazione a basso livello lavorano più da vicino con l'hardware e hanno maggiore controllo su di esso. Interagiscono direttamente con l'hardware. Due esempi comuni di linguaggi a basso livello sono il linguaggio macchina e il linguaggio assembly. Questi sono generalmente più veloci dei linguaggi ad alto livello, ma a costo di una maggiore difficoltà e minore leggibilità.

### [Paradigmi di Programmazione](/Programming_Languages/readme.md#Programming+Paradigms)
Esistono anche diversi *paradigmi di programmazione*. I paradigmi di programmazione sono diversi modi o stili in cui un dato programma o linguaggio di programmazione può essere organizzato. Ogni paradigma consiste di certe strutture, caratteristiche e opinioni su come affrontare i problemi di programmazione comuni.

I paradigmi di programmazione *non* sono linguaggi o strumenti. Non puoi "costruire" nulla con un paradigma. Sono più simili a un insieme di ideali e linee guida che molte persone hanno accettato, seguito e ampliato. I linguaggi di programmazione non sono sempre legati a un particolare paradigma. Ci *sono* linguaggi che sono stati costruiti con un certo paradigma in mente e hanno caratteristiche che facilitano quel tipo di programmazione più di altri (Haskell e la programmazione funzionale sono un buon esempio). Ma ci sono anche linguaggi "multi-paradigma" in cui puoi adattare il tuo codice per adattarsi a un paradigma o all'altro (JavaScript e Python sono buoni esempi).


## [Tipi di Dati](Data%20Types/readme.md#data-types)
Un tipo di dati, nella programmazione, è una classificazione che specifica quale tipo di valore ha una variabile e quale tipo di operazioni matematiche, relazionali o logiche possono essere applicate ad essa senza causare errori.

### [Tipi di Dati Primitivi](Data%20Types/readme.md#primitive-data-types)
I tipi di dati primitivi sono i tipi di dati più basilari in un linguaggio di programmazione. Sono i mattoni di costruzione dei tipi di dati più complessi. I tipi di dati primitivi sono predefiniti dal linguaggio di programmazione e sono nominati da una parola chiave riservata.

### [Tipi di Dati Primitivi Comuni](Data%20Types/readme.md#common-primitive-data-types)
- [Intero](Data%20Types/readme.md#integer)
- [Virgola Mobile](Data%20Types/readme.md#float)
- [Booleano](Data%20Types/readme.md#boolean)
- [Carattere](Data%20Types/readme.md#character)
- [Stringa](Data%20Types/readme.md#string)

### [Tipi di Dati Non Primitivi](Data%20Types/read

me.md#non-primitive-data-types)
I tipi di dati non primitivi sono anche noti come tipi di dati di riferimento. Sono creati dal programmatore e non sono definiti dal linguaggio di programmazione. I tipi di dati non primitivi sono anche chiamati tipi di dati compositi perché sono composti da altri tipi.

### [Tipi di Dati Non Primitivi Comuni](Data%20Types/readme.md#common-non-primitive-data-types)
- [Array](Data%20Types/readme.md#array)
- [Struct](Data%20Types/readme.md#struct)
- [Unione](Data%20Types/readme.md#union)
- [Puntatore](Data%20Types/readme.md#pointer)
- [Funzione](Data%20Types/readme.md#function)
- [Classe](Data%20Types/readme.md#class)

## [Istruzioni e Funzioni](Statements%20and%20Functions/readme.md)
Nella programmazione, un'istruzione è un'unità sintattica di un linguaggio di programmazione imperativo che esprime un'azione da eseguire. Un programma scritto in tale linguaggio è formato da una sequenza di una o più istruzioni. Un'istruzione può avere componenti interni (ad esempio, espressioni).
Ci sono due tipi principali di istruzioni in qualsiasi linguaggio di programmazione necessari per costruire la logica di un codice.

1. [Istruzioni Condizionali](Statements%20and%20Functions/readme.md#conditional-statements)

Esistono principalmente due tipi di istruzioni condizionali:
- if
- if-else
- switch case

2. [Cicli](Statements%20and%20Functions/readme.md#loops)

Esistono principalmente tre tipi di cicli:
- for loop
- while loop
- do-while loop (una variazione del while loop)
- do-until loop

------------

Una funzione è un blocco di istruzioni che svolge un compito specifico. Le funzioni accettano dati, li elaborano e restituiscono un risultato o eseguono un'azione. Le funzioni sono scritte principalmente per supportare il concetto di riutilizzabilità. Una volta scritta una funzione, può essere chiamata facilmente senza dover ripetere lo stesso codice.

Diversi linguaggi funzionali utilizzano sintassi diverse per scrivere le funzioni.

Leggi di più sulle funzioni [qui](Statements%20and%20Functions/readme.md#functions).


## [Strutture Dati](Data%20Structures/readme.md)
In informatica, una struttura dati è un formato per l'organizzazione, la gestione e l'archiviazione dei dati che consente un accesso e una modifica efficienti. Più precisamente, una struttura dati è una raccolta di valori di dati, le relazioni tra di essi e le funzioni o operazioni che possono essere applicate ai dati.

### Tipi di Strutture Dati
- [Array](Data%20Structures/readme.md#array)
- [Lista Collegata](Data%20Structures/readme.md#linkedlist)
- [Stack](Data%20Structures/readme.md#stack)
- [Coda](Data%20Structures/readme.md#queue)
- [Tabella Hash](Data%20Structures/readme.md#hashtable)
- [Heap](Data%20Structures/readme.md#heap)
- [Albero](Data%20Structures/readme.md#tree)
- [Grafo](Data%20Structures/readme.md#graph)

## [Algoritmi](Algorithms/readme.md)
Gli algoritmi sono insiemi di passi necessari per completare un calcolo. Sono al cuore di ciò che fanno i nostri dispositivi, e non è un concetto nuovo. Dallo sviluppo della matematica stessa, sono stati necessari algoritmi per aiutarci a completare i compiti in modo più efficiente. Oggi daremo uno sguardo a un paio di problemi di calcolo moderni, come l'ordinamento e la ricerca sui grafi, e mostreremo come li abbiamo resi più efficienti affinché tu possa trovare più facilmente voli economici o indicazioni stradali verso Winterfell o un ristorante o altro.

### [Complessità Temporale](Algorithms/Time%20Complexity/readme.md)
La complessità temporale di un algoritmo stima quanto tempo l'algoritmo impiegherà per un certo input. L'idea è di rappresentare l'efficienza come una funzione il cui parametro è la dimensione dell'input. Calcolando la complessità temporale, possiamo determinare se l'algoritmo è abbastanza veloce senza implementarlo.

### [Complessità Spaziale](Algorithms/Space%20Complexity/readme.md)
La complessità spaziale si riferisce alla quantità totale di memoria che un algoritmo/program utilizza, inclusa la memoria degli input necessari per l'esecuzione. Calcolare lo spazio occupato dalle variabili in un algoritmo/program permette di determinare la complessità spaziale.

### [Ordinamento](Algorithms/Sorting/readme.md)
L'ordinamento è il processo di disposizione di un elenco di elementi in un ordine particolare. Ad esempio, se avessi un elenco di nomi, potresti volerli ordinare in ordine alfabetico. In alternativa, se avessi un elenco di numeri, potresti volerli mettere in ordine dal più piccolo al più grande. L'ordinamento è un compito comune, e possiamo farlo in molti modi diversi.

### [Ricerca](Algorithms/Searching/readme.md)
La ricerca è un algoritmo per trovare un certo elemento target all'interno di un contenitore. Gli algoritmi di ricerca sono progettati per verificare la presenza di un elemento o recuperare un elemento da qualsiasi struttura dati in cui è archiviato.

### [Algoritmi Basati su Stringhe](Algorithms/String%20Based%20Algorithms/readme.md)
Le stringhe sono una delle strutture dati più utilizzate e importanti nella programmazione. Questo repository contiene alcuni degli algoritmi più utilizzati che aiutano a migliorare il tempo di ricerca, ottimizzando il nostro codice.

### [Ricerca sui Grafi](Algorithms/Graph/readme.md)
La ricerca sui grafi è il processo di ricerca attraverso un grafo per trovare un particolare nodo. Un grafo è una struttura dati che consiste in un insieme finito (e possibilmente mutabile) di vertici o nodi o punti, insieme a un insieme di coppie non ordinate di questi vertici per un grafo non orientato o un insieme di coppie ordinate per un grafo orientato. Queste coppie sono conosciute come archi, archi orientati o linee per un grafo non orientato e come frecce, archi diretti, archi diretti o linee dirette per un grafo orientato. I vertici possono far parte della struttura del grafo o possono essere entità esterne rappresentate da indici interi o riferimenti. I grafi sono una delle strutture dati più utili per molte applicazioni nel mondo reale. I grafi sono utilizzati per modellare relazioni a coppie tra oggetti. Ad esempio, la rete delle rotte aeree è un grafo in cui le città sono i vertici e le rotte dei voli sono gli archi. I grafi sono anche usati per rappresentare reti. Internet può essere modellato come un grafo in cui i computer sono i vertici e i collegamenti tra i computer sono gli archi. I grafi sono anche utilizzati nei social network come LinkedIn e Facebook. I grafi sono utilizzati per rappresentare molte applicazioni del mondo reale: reti informatiche, progettazione di circuiti, e programmazione aeronautica, solo per citarne alcune.

### [Programmazione Dinamica](Algorithms/Dynamic%20Programming/README.md)
La programmazione dinamica è sia un metodo di ottimizzazione matematica che un metodo di programmazione informatica. Richard Bellman sviluppò il metodo negli anni '50 e ha trovato applicazioni in numerosi campi, dall'ingegneria aerospaziale all'economia. In entrambi i contesti, si riferisce a semplificare un problema complicato suddividendolo in sottoproblemi più semplici in modo ricorsivo. Anche se alcuni problemi decisionali non possono essere scomposti in questo modo, le decisioni che si estendono su più punti nel tempo spesso si scompongono ricorsivamente. Allo stesso modo, in informatica, se un problema può essere risolto in modo ottimale suddividendolo in sottoproblemi e poi trovando ricorsivamente le soluzioni ottimali ai sottoproblemi, allora si dice che ha una struttura ottimale. La programmazione dinamica è uno dei modi per risolvere problemi con queste proprietà. Il processo di suddivisione di un problema complicato in sottoproblemi più semplici è chiamato "divide et impera".

### [Algoritmi Greedy](Algorithms/Greedy%20Algorithm/readme.md)
Gli algoritmi greedy sono una classe di algoritmi semplice e intuitiva che può essere utilizzata per trovare la soluzione ottimale a problemi di ottimizzazione. Sono chiamati greedy perché, a ogni passo, fanno la scelta che sembra migliore in quel momento. Questo significa che gli algoritmi greedy non garantiscono di restituire la soluzione ottimale globale, ma invece fanno scelte localmente ottimali nella speranza di trovare un ottimo globale. Gli algoritmi greedy sono utilizzati per problemi di ottimizzazione. Un problema di ottimizzazione può essere risolto utilizzando Greedy se il problema ha la seguente proprietà: a ogni passo, possiamo fare una scelta che sembra migliore al momento e ottenere la soluzione ottimale al problema completo.

### [Backtracking](Algorithms/Backtracking/README.md)
Il backtracking è una tecnica algoritmica per risolvere problemi in modo ricorsivo cercando di costruire una soluzione incrementale, un pezzo alla volta, rimuovendo quelle soluzioni che non soddisfano i vincoli del problema in qualsiasi punto del tempo (il tempo qui si riferisce al tempo trascorso fino a raggiungere qualsiasi livello dell'albero di ricerca).

### [Branch and Bound](Algorithms/Branch%20and%20Bound/README.md)
Branch and Bound è una tecnica generale per risolvere problemi di ottimizzazione combinatoria. È una tecnica di enumerazione sistematica che riduce il numero di soluzioni candidate utilizzando la struttura del problema per eliminare soluzioni candidate che non possono essere ottimali.

### [Complessità Temporale e Complessità Spaziale di Diversi Algoritmi di Ricerca e Ordinamento](Not-Added)
**Complessità Temporale**: È definita come il numero di volte che un particolare set di istruzioni si prevede venga eseguito piuttosto che il tempo totale impiegato. Poiché il tempo è un fenomeno dipendente, la complessità temporale può variare in base ad alcuni fattori esterni come la velocità del processore, il compilatore utilizzato, ecc.

**Complessità Spaziale**: È lo spazio totale di memoria consumato dal programma per la sua esecuzione.

Entrambi sono calcolati come funzione della dimensione dell'input (n). La complessità temporale di un algoritmo è espressa in notazione big O.

L'efficienza di un algoritmo dipende da questi due parametri.

### Tipi di Complessità Temporale:

- **Complessità Temporale nel Migliore dei Casi**: L'input per cui l'algoritmo impiega meno tempo o il tempo minimo. Nel migliore dei casi, calcoliamo la complessità temporale del limite inferiore di un algoritmo. Ad esempio: se i dati da cercare sono presenti nella prima posizione di un grande array di dati in una ricerca lineare, allora si verifica il migliore dei casi.

- **Complessità Temporale Media**: Prendiamo tutti gli input casuali e calcoliamo il tempo di elaborazione per tutti gli input. Poi, lo dividiamo per il numero totale di input.

- **Complessità Temporale nel Peggiore dei Casi**: Definisce l'input per cui l'algoritmo impiega più tempo o il tempo massimo. Nel peggiore dei casi, calcoliamo il limite superiore di un algoritmo. Esempio: Se i dati da cercare sono presenti nell'ultima posizione di un grande array di dati in un algoritmo di ricerca lineare, allora si verifica il peggiore dei casi.

Alcune complessità temporali comuni sono:

- **O(1)**: Questo denota il tempo costante. O(1) di solito significa che un algoritmo avrà un tempo costante indipendentemente dalla dimensione dell'input. Gli Hash Map sono perfetti esempi di tempo costante.

- **O(log n)**: Questo denota il tempo logaritmico. O(log n) significa che diminuisce a ogni iterazione per le operazioni. Cercare elementi negli Alberi di Ricerca Binari (BST) è un buon esempio di tempo logaritmico.

- **O(n)**: Questo denota il tempo lineare. O(n) significa che le prestazioni sono direttamente proporzionali alla dimensione dell'input. In termini semplici, il numero di input e il tempo impiegato per eseguire quegli input saranno proporzionali. La ricerca lineare negli array è un ottimo esempio di complessità temporale lineare.

- **O(n\*n)**: Questo denota il tempo quadratico. O(n^2) significa che le prestazioni sono direttamente proporzionali al quadrato dell'input preso. In modo semplice, il tempo impiegato per l'esecuzione richiederà grosso modo il quadrato della dimensione dell'input. I cicli annidati sono perfetti esempi di complessità temporale quadratica.

- **O(n log n)**: Questo denota la complessità temporale polinomiale. O(n log n) significa che le prestazioni sono n volte quelle di O(log n), (che è la complessità nel peggiore dei casi). Un buon esempio sarebbe un algoritmo di divide et impera come il merge sort. Questo algoritmo prima divide l'insieme, che richiede O(log n) tempo, poi affronta e ordina l'insieme, che richiede O(n) tempo; quindi, il merge sort richiede O(n log n) tempo.

| Algoritmo	     |             |  Complessità Temporale |	       | Complessità Spaziale |
|   :---:        |  :---:      |  :---: 	   |   :---: 	   |   :---:          |
|  	             | Migliore	   | Media	         |  Peggiore	     |  Peggiore         |
| Selection Sort | Ω(n^2)	     | θ(n^2)	     | O(n^2)	       | O(1)             |
| Bubble Sort	 | Ω(n)	       | θ(n^2)	     | O(n^2)	       | O(1)             |
| Insertion Sort | Ω(n)	       | θ(n^2)	     | O(n^2)	       | O(1)             |
| Heap Sort	     | Ω(n log(n)) | θ(n log(n)) | O(n log(n)) | O(1)             |
| Quick Sort	   | Ω(n log(n)) | θ(n log(n)) | O(n^2)	     | O(n)             |
| Merge Sort	   | Ω(n log(n)) | θ(n log(n)) | O(n log(n)) | O(n)             |
| Bucket Sort    | Ω(n +k)	   | θ(n +k)	   | O(n^2)	     | O(n)             |
| Radix Sort  	 | Ω(nk)	     | θ(nk)	     | O(nk)	       | O(n + k)         |
| Count Sort  	 | Ω(n +k)	   | θ(n +k)	   | O(n +k)	     | O(k)             |
| Shell Sort  	 | Ω(n log(n)) | θ(n log(n)) | O(n^2)	     | O(1)             |
| Tim Sort	     | Ω(n)	       | θ(n log(n)) | O(n log(n)) | O(n)             |
| Tree Sort   	 | Ω(n log(n)) | θ(n log(n)) | O(n^2)	     | O(n)             |
| Cube Sort	     | Ω(n)	       | θ(n log(n)) | O(n log(n)) | O(n)             |

| Algoritmo	     |             |  Complessità Temporale |	     |
|   :---:        |  :---:      |  :---: 	 |   :---: 	   |  
|  	             | Migliore	   | Media	   |  Peggiore	     |
| Linear Search  | O(1)	       | O(N)	     | O(N)	         | O(1)  |
| Binary Search	 | O(1)	       | O(logN)   | O(logN)	     |


## [Alan Turing](Not-Added)
Alan Turing (nato il 23 giugno 1912, Londra, Inghilterra – morto il 7 giugno 1954, Wilmslow, Cheshire) è stato un matematico e logico inglese. Ha studiato presso l'Università di Cambridge e l'Istituto per gli Studi Avanzati di Princeton. Nel suo influente articolo del 1936 "On Computable Numbers", dimostrò che non poteva esistere alcun metodo algoritmico universale per determinare la verità in matematica e che la matematica conterrà sempre proposizioni indecidibili (a differenza delle proposizioni sconosciute). Quel documento introdusse anche la macchina di Turing. Credeva che i computer sarebbero stati capaci di pensiero indistinguibile da quello umano e propose un semplice test (vedi Turing test) per valutare questa capacità. I suoi articoli sull'argomento sono ampiamente riconosciuti come le fondamenta della ricerca sull'intelligenza artificiale. Fece un lavoro prezioso nella crittografia durante la Seconda Guerra Mondiale, svolgendo un ruolo importante nella decodifica del codice Enigma utilizzato dalla Germania per le comunicazioni radio. Dopo la guerra, insegnò presso l'Università di Manchester e iniziò a lavorare su quello che oggi è conosciuto come intelligenza artificiale. In mezzo a questo lavoro rivoluzionario, Turing fu trovato morto nel suo letto, avvelenato dal cianuro. La sua morte seguì il suo arresto per un atto omosessuale (all'epoca un reato) e la condanna a 12 mesi di terapia ormonale.

A seguito di una campagna pubblica nel 2009, il Primo Ministro britannico Gordon Brown fece una scusa pubblica ufficiale a nome del governo britannico per il trattamento orribile riservato a Turing. La Regina Elisabetta II concesse un perdono postumo nel 2013. Il termine "Alan Turing law" è ora usato informalmente per riferirsi a una legge del 2017 nel Regno Unito che ha concesso il perdono retroattivo agli uomini ammoniti o condannati sotto la legislazione storica che vietava gli atti omosessuali.

Turing ha un'estesa eredità con statue di lui e molte cose a lui intitolate, tra cui un premio annuale per le innovazioni in informatica. Appare sulla banconota da £50 della Bank of England, rilasciata il 23 giugno 2021, in coincidenza con il suo compleanno. Una serie della BBC del 2019, votata dal pubblico, lo ha nominato la più grande persona del 20° secolo.


## [Ingegneria del Software](Software%20Engineering/readme.md)
L'ingegneria del software è il ramo dell'informatica che si occupa della progettazione, dello sviluppo, del collaudo e della manutenzione delle applicazioni software. Gli ingegneri del software applicano i principi dell'ingegneria e la conoscenza dei linguaggi di programmazione per creare soluzioni software per gli utenti finali.

Vediamo le varie definizioni di ingegneria del software:

- IEEE, nel suo standard 610.12-1990, definisce l'ingegneria del software come l'applicazione di un approccio sistematico, disciplinato e calcolabile per lo sviluppo, l'operazione e la manutenzione del software.
- Fritz Bauer la definisce come "l'istituzione e l'uso di principi ingegneristici standard. Aiuta a ottenere software economico, affidabile e che funziona

 in modo efficiente su macchine reali."
- Boehm definisce l'ingegneria del software come "l'applicazione pratica della conoscenza scientifica alla progettazione creativa e alla costruzione di programmi per computer. Include anche la documentazione associata necessaria per svilupparli, gestirli e mantenerli."

### Compiti e responsabilità dell'ingegnere del software
Gli ingegneri di successo sanno come utilizzare i giusti linguaggi di programmazione, piattaforme e architetture per sviluppare tutto, dai giochi per computer ai sistemi di controllo della rete. Oltre a costruire i propri sistemi, gli ingegneri del software testano, migliorano e mantengono anche il software sviluppato da altri ingegneri.

In questo ruolo, le tue attività quotidiane potrebbero includere:

- Progettare e mantenere sistemi software
- Valutare e testare nuovi programmi software
- Ottimizzare il software per velocità e scalabilità
- Scrivere e testare codice
- Consultarsi con clienti, ingegneri, specialisti della sicurezza e altre parti interessate
- Presentare nuove funzionalità alle parti interessate e ai clienti interni

### Fasi dell'Ingegneria del Software
Il processo di ingegneria del software comprende diverse fasi, tra cui la raccolta dei requisiti, la progettazione, l'implementazione, il collaudo e la manutenzione. Seguendo un approccio disciplinato allo sviluppo del software, gli ingegneri del software possono creare software di alta qualità che soddisfa le esigenze degli utenti.

- La prima fase dell'ingegneria del software è la raccolta dei requisiti. In questa fase, l'ingegnere del software lavora con il cliente per determinare i requisiti funzionali e non funzionali del software. I requisiti funzionali descrivono cosa dovrebbe fare il software, mentre i requisiti non funzionali descrivono come dovrebbe farlo. La raccolta dei requisiti è una fase critica, poiché pone le basi per l'intero processo di sviluppo del software.

- Dopo la raccolta dei requisiti, la fase successiva è la progettazione. In questa fase, l'ingegnere del software crea un piano dettagliato per l'architettura e la funzionalità del software. Questo piano include un documento di progettazione del software che specifica la struttura, il comportamento e le interazioni del software con altri sistemi. Il documento di progettazione del software è essenziale poiché funge da guida per la fase di implementazione.

- La fase di implementazione è dove l'ingegnere del software crea il codice effettivo per il software. Questo è il momento in cui il documento di progettazione viene trasformato in software funzionante. La fase di implementazione comprende la scrittura del codice, la compilazione e il collaudo per garantire che soddisfi i requisiti specificati nel documento di progettazione.

- Il collaudo è una fase critica nell'ingegneria del software. In questa fase, l'ingegnere del software verifica che il software funzioni correttamente, sia affidabile e facile da usare. Questo coinvolge diversi tipi di collaudo, tra cui collaudo unitario, collaudo di integrazione e collaudo del sistema. Il collaudo assicura che il software soddisfi i requisiti e funzioni come previsto.

- L'ultima fase dell'ingegneria del software è la manutenzione. In questa fase, l'ingegnere del software apporta modifiche al software per correggere errori, aggiungere nuove funzionalità o migliorare le prestazioni. La manutenzione è un processo continuo che continua per tutta la durata del software.

### Perché l'Ingegneria del Software è Popolare?

- **Informatica**: Fornisce le basi scientifiche per il software così come l'ingegneria elettrica dipende principalmente dalla fisica.
- **Scienze Gestionali**: L'ingegneria del software è intensiva dal punto di vista del lavoro e richiede controllo tecnico e manageriale. Pertanto, è ampiamente utilizzata nelle scienze gestionali.
- **Economia**: In questo settore, l'ingegneria del software aiuta a stimare le risorse e controllare i costi. Un sistema informatico deve essere sviluppato e i dati devono essere mantenuti regolarmente all'interno di un budget definito.
- **Ingegneria dei Sistemi**: La maggior parte del software è un componente di un sistema molto più grande. Ad esempio, il software in un sistema di monitoraggio industriale o il software di volo su un aereo. I metodi di ingegneria del software dovrebbero essere applicati allo studio di questo tipo di sistema.


